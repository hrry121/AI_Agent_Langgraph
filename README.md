# ğŸ¤– AI_Agent_Langgraph

This project demonstrates the implementation of LangGraph, a framework for orchestrating multiple collaborative agents to handle complex queries. It features various specialized agentsâ€”Plan Agent, Tool Agent, Reflection Agent, Feedback Agent, and moreâ€”working together to decompose, solve, and refine user tasks.

When a user provides a high-level or open-ended query, the system intelligently splits it into subtasks and returns a detailed, refined response after iterative feedback and reflection.

---

## ğŸ§° Tech Stack

- LangGraph â€“ Agent orchestration framework

- LangChain â€“ LLM tooling and chain composition

- Gradio â€“ Interactive chat interface

- Python â€“ Core programming language

- Groq + LLaMA-3 â€“ High-performance LLM backend
---
ğŸ§  Agents Used

ğŸ“ Plan Agent â€“ Breaks down complex queries into subtasks

ğŸ”§ Tool Agent â€“ Executes each subtask using available tools

ğŸª„ Task Refiner â€“ Improves clarity, order, or necessity of subtasks

âœ… Feedback Agent â€“ Evaluates & improves subtask results

ğŸ” Reflection Agent â€“ Assesses overall coherence and quality

ğŸ Output Agent â€“ Aggregates and finalizes the response

---

## ğŸ” Features
ğŸ§  Multi-Agent Collaboration Loop:

- ğŸ“ Plan Agent breaks down complex queries into smaller, manageable subtasks

- ğŸ”§ Tool Agent executes each subtask using external tools or LLMs

- ğŸ” Reflection Agent evaluates whether the response is complete and suggests new or improved subtasks if necessary

- âœ… Feedback Agent reviews each result for correctness, completeness, usefulness, and clarity

- ğŸª„ Task Refiner removes duplicates, merges related tasks, and adds or prunes subtasks to streamline execution

- ğŸ” This feedback-reflection loop continues iteratively until all tasks are resolved with high quality

- ğŸ Output Agent formats the final response in a clean and structured manner for the user

- ğŸ’¬ Interactive and minimal Gradio UI for chat-like interactions

- âš¡ Fast and accurate responses powered by Groq Cloud (LLaMA-3) backend
---
## ğŸŒ Live Demo

https://huggingface.co/spaces/hrry121/AI_Agent_Langgraph

---
## ğŸš€ Getting Started (Optional)

### ğŸ“¦ Clone the Repository

```bash
git clone https://github.com/hrry121/AI_Agent_Langgraph.git
```

### ğŸ”‘ Set Up Environment Variables

Create a `.env` file in the root directory with the following content:

```env
GROQ_API_KEY=your_api_key_here
```
This is necessary to access the Groq-powered LLM backend.

---

### ğŸ“¥ Install Requirements

```bash
pip install -r requirements.txt
```
---
## ğŸª„ Example Prompts:

How to cook rice,Plan me a study schedule,etc.

---
## Result will looklike:
![image](https://github.com/user-attachments/assets/656f4b05-fe82-4669-92c7-bbc5464985c9)

ğŸ§‘â€ğŸ’» Author
Built with â¤ï¸ by Isha Patil
ğŸ“¬ Feel free to contribute, fork, or connect!
